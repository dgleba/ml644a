Sun Jul 17 13:35:47 2022       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 465.19.01    Driver Version: 465.19.01    CUDA Version: 11.3     |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|                               |                      |               MIG M. |
|===============================+======================+======================|
|   0  NVIDIA A100-SXM...  On   | 00000000:00:05.0 Off |                    0 |
| N/A   24C    P0    40W / 400W |    124MiB / 40536MiB |      0%      Default |
|                               |                      |             Disabled |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                                  |
|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |
|        ID   ID                                                   Usage      |
|=============================================================================|
|    0   N/A  N/A      1195      G   /usr/lib/xorg/Xorg                 81MiB |
|    0   N/A  N/A      1832      G   /usr/bin/gnome-shell               42MiB |
+-----------------------------------------------------------------------------+
Linux psdw6rhji 5.4.0-105-generic #119-Ubuntu SMP Mon Mar 7 18:49:24 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux
              total        used        free      shared  buff/cache   available
Mem:           88Gi       1.0Gi        81Gi        11Mi       5.4Gi        86Gi
Swap:            0B          0B          0B
DISTRIB_ID=Ubuntu
DISTRIB_RELEASE=20.04
DISTRIB_CODENAME=focal
DISTRIB_DESCRIPTION="Ubuntu 20.04.3 LTS"
Filesystem                   Size  Used Avail Use% Mounted on
udev                          45G     0   45G   0% /dev
tmpfs                        8.9G  1.4M  8.9G   1% /run
/dev/mapper/ubuntu--vg-root   50G   36G   12G  77% /
tmpfs                         45G     0   45G   0% /dev/shm
tmpfs                        5.0M     0  5.0M   0% /run/lock
tmpfs                         45G     0   45G   0% /sys/fs/cgroup
/dev/loop0                    56M   56M     0 100% /snap/core18/2344
/dev/loop1                    62M   62M     0 100% /snap/core20/1376
/dev/loop2                    56M   56M     0 100% /snap/core18/2409
/dev/loop3                    62M   62M     0 100% /snap/core20/1518
/dev/loop5                    68M   68M     0 100% /snap/lxd/22526
/dev/loop4                    68M   68M     0 100% /snap/lxd/21835
/dev/loop6                    44M   44M     0 100% /snap/snapd/14978
/dev/loop7                    44M   44M     0 100% /snap/snapd/15177
tmpfs                        8.9G   20K  8.9G   1% /run/user/1000
/dev/loop8                    47M   47M     0 100% /snap/snapd/16292
 # SSD with EfficientNet-b0 + BiFPN feature extractor,
# shared box predictor and focal loss (a.k.a EfficientDet-d0).
# See EfficientDet, Tan et al, https://arxiv.org/abs/1911.09070
# See Lin et al, https://arxiv.org/abs/1708.02002
# Trained on COCO, initialized from an EfficientNet-b0 checkpoint.
#
# Train on TPU-8

model {
  ssd {
    inplace_batchnorm_update: true
    freeze_batchnorm: false
    num_classes: 2
    add_background_class: false
    box_coder {
      faster_rcnn_box_coder {
        y_scale: 10.0
        x_scale: 10.0
        height_scale: 5.0
        width_scale: 5.0
      }
    }
    matcher {
      argmax_matcher {
        matched_threshold: 0.5
        unmatched_threshold: 0.5
        ignore_thresholds: false
        negatives_lower_than_unmatched: true
        force_match_for_each_row: true
        use_matmul_gather: true
      }
    }
    similarity_calculator {
      iou_similarity {
      }
    }
    encode_background_as_zeros: true
    anchor_generator {
      multiscale_anchor_generator {
        min_level: 3
        max_level: 7
        anchor_scale: 4.0
        aspect_ratios: [1.0, 2.0, 0.5]
        scales_per_octave: 3
      }
    }
    image_resizer {
      keep_aspect_ratio_resizer {
        min_dimension: 256
        max_dimension: 896
        pad_to_max_dimension: true
        }
    }
    box_predictor {
      weight_shared_convolutional_box_predictor {
        depth: 64
        class_prediction_bias_init: -4.6
        conv_hyperparams {
          force_use_bias: true
          activation: SWISH
          regularizer {
            l2_regularizer {
              weight: 0.00004
            }
          }
          initializer {
            random_normal_initializer {
              stddev: 0.01
              mean: 0.0
            }
          }
          batch_norm {
            scale: true
            decay: 0.99
            epsilon: 0.001
          }
        }
        num_layers_before_predictor: 3
        kernel_size: 3
        use_depthwise: true
      }
    }
    feature_extractor {
      type: 'ssd_efficientnet-b0_bifpn_keras'
      bifpn {
        min_level: 3
        max_level: 7
        num_iterations: 3
        num_filters: 64
      }
      conv_hyperparams {
        force_use_bias: true
        activation: SWISH
        regularizer {
          l2_regularizer {
            weight: 0.00004
          }
        }
        initializer {
          truncated_normal_initializer {
            stddev: 0.03
            mean: 0.0
          }
        }
        batch_norm {
          scale: true,
          decay: 0.99,
          epsilon: 0.001,
        }
      }
    }
    loss {
      classification_loss {
        weighted_sigmoid_focal {
          alpha: 0.25
          gamma: 1.5
        }
      }
      localization_loss {
        weighted_smooth_l1 {
        }
      }
      classification_weight: 1.0
      localization_weight: 1.0
    }
    normalize_loss_by_num_matches: true
    normalize_loc_loss_by_codesize: true
    post_processing {
      batch_non_max_suppression {
        score_threshold: 1e-8
        iou_threshold: 0.5
        max_detections_per_class: 100
        max_total_detections: 100
      }
      score_converter: SIGMOID
    }
  }
}

train_config: {
  fine_tune_checkpoint: "../tflib/efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0"
  fine_tune_checkpoint_version: V2
  fine_tune_checkpoint_type: "detection"
  batch_size: 1
  sync_replicas: true
  startup_delay_steps: 0
  replicas_to_aggregate: 8
  use_bfloat16: true
  num_steps: 8000
  data_augmentation_options {
    random_horizontal_flip {
    }
  }
  optimizer {
    momentum_optimizer: {
      learning_rate: {
        cosine_decay_learning_rate {
          learning_rate_base: 8e-2
          total_steps: 300000
          warmup_learning_rate: .001
          warmup_steps: 2500
        }
      }
      momentum_optimizer_value: 0.9
    }
    use_moving_average: false
  }
  max_number_of_boxes: 100
  unpad_groundtruth_tensors: false
}

train_input_reader: {
  label_map_path: "../imgdata/ir4/labelmap.pbtxt"
  tf_record_input_reader {
    input_path: "../imgdata/ir4/train.record"
  }
}

eval_config: {
  metrics_set: "coco_detection_metrics"
  use_moving_averages: false
  batch_size: 1;
}

eval_input_reader: {
  label_map_path: "../imgdata/ir4/labelmap.pbtxt"
  shuffle: false
  num_epochs: 1
  tf_record_input_reader {
    input_path: "../imgdata/ir4/test.record"
  }
}
2022-07-17 13:36:01.278656: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-07-17 13:36:01.568683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-07-17 13:36:01.573254: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-07-17 13:36:01.579029: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-07-17 13:36:01.581617: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-07-17 13:36:01.586081: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-07-17 13:36:01.590405: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-07-17 13:36:03.514922: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-07-17 13:36:03.519443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-07-17 13:36:03.523769: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:975] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
2022-07-17 13:36:03.528012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1532] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 38295 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:05.0, compute capability: 8.0
INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
I0717 13:36:05.334553 140137644001088 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)
INFO:tensorflow:Maybe overwriting train_steps: 8000
I0717 13:36:05.344414 140137644001088 config_util.py:552] Maybe overwriting train_steps: 8000
INFO:tensorflow:Maybe overwriting use_bfloat16: False
I0717 13:36:05.344761 140137644001088 config_util.py:552] Maybe overwriting use_bfloat16: False
I0717 13:36:05.365240 140137644001088 ssd_efficientnet_bifpn_feature_extractor.py:145] EfficientDet EfficientNet backbone version: efficientnet-b0
I0717 13:36:05.365562 140137644001088 ssd_efficientnet_bifpn_feature_extractor.py:147] EfficientDet BiFPN num filters: 64
I0717 13:36:05.365720 140137644001088 ssd_efficientnet_bifpn_feature_extractor.py:148] EfficientDet BiFPN num iterations: 3
I0717 13:36:05.378911 140137644001088 efficientnet_model.py:143] round_filter input=32 output=32
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0717 13:36:05.946758 140137644001088 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0717 13:36:05.951469 140137644001088 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0717 13:36:05.957189 140137644001088 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0717 13:36:05.959532 140137644001088 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0717 13:36:05.978099 140137644001088 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0717 13:36:05.987286 140137644001088 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0717 13:36:06.002578 140137644001088 efficientnet_model.py:143] round_filter input=32 output=32
I0717 13:36:06.002906 140137644001088 efficientnet_model.py:143] round_filter input=16 output=16
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0717 13:36:06.039241 140137644001088 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0717 13:36:06.041806 140137644001088 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0717 13:36:06.046025 140137644001088 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0717 13:36:06.048244 140137644001088 cross_device_ops.py:616] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).
I0717 13:36:06.256429 140137644001088 efficientnet_model.py:143] round_filter input=16 output=16
I0717 13:36:06.256815 140137644001088 efficientnet_model.py:143] round_filter input=24 output=24
I0717 13:36:06.936046 140137644001088 efficientnet_model.py:143] round_filter input=24 output=24
I0717 13:36:06.936421 140137644001088 efficientnet_model.py:143] round_filter input=40 output=40
I0717 13:36:07.610666 140137644001088 efficientnet_model.py:143] round_filter input=40 output=40
I0717 13:36:07.611047 140137644001088 efficientnet_model.py:143] round_filter input=80 output=80
I0717 13:36:08.591802 140137644001088 efficientnet_model.py:143] round_filter input=80 output=80
I0717 13:36:08.592198 140137644001088 efficientnet_model.py:143] round_filter input=112 output=112
I0717 13:36:09.574066 140137644001088 efficientnet_model.py:143] round_filter input=112 output=112
I0717 13:36:09.574482 140137644001088 efficientnet_model.py:143] round_filter input=192 output=192
I0717 13:36:10.891583 140137644001088 efficientnet_model.py:143] round_filter input=192 output=192
I0717 13:36:10.891970 140137644001088 efficientnet_model.py:143] round_filter input=320 output=320
I0717 13:36:11.211046 140137644001088 efficientnet_model.py:143] round_filter input=1280 output=1280
I0717 13:36:11.535957 140137644001088 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')
WARNING:tensorflow:From /home/paperspace/.local/lib/python3.8/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.
Instructions for updating:
rename to distribute_datasets_from_function
W0717 13:36:11.650360 140137644001088 deprecation.py:350] From /home/paperspace/.local/lib/python3.8/site-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.
Instructions for updating:
rename to distribute_datasets_from_function
INFO:tensorflow:Reading unweighted datasets: ['../imgdata/ir4/train.record']
I0717 13:36:11.659204 140137644001088 dataset_builder.py:162] Reading unweighted datasets: ['../imgdata/ir4/train.record']
INFO:tensorflow:Reading record datasets for input file: ['../imgdata/ir4/train.record']
I0717 13:36:11.659802 140137644001088 dataset_builder.py:79] Reading record datasets for input file: ['../imgdata/ir4/train.record']
INFO:tensorflow:Number of filenames to read: 1
I0717 13:36:11.660109 140137644001088 dataset_builder.py:80] Number of filenames to read: 1
WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.
W0717 13:36:11.660379 140137644001088 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.
WARNING:tensorflow:From /home/paperspace/.local/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.
W0717 13:36:11.665535 140137644001088 deprecation.py:350] From /home/paperspace/.local/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.
WARNING:tensorflow:From /home/paperspace/.local/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
W0717 13:36:11.720773 140137644001088 deprecation.py:350] From /home/paperspace/.local/lib/python3.8/site-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.data.Dataset.map()
WARNING:tensorflow:From /home/paperspace/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
W0717 13:36:29.205094 140137644001088 deprecation.py:350] From /home/paperspace/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.
WARNING:tensorflow:From /home/paperspace/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
W0717 13:36:36.438736 140137644001088 deprecation.py:350] From /home/paperspace/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.
Instructions for updating:
Use `tf.cast` instead.
2022-07-17 13:37:45.584445: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8201
2022-07-17 13:37:53.072549: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
2022-07-17 13:38:04.123213: I tensorflow/stream_executor/cuda/cuda_blas.cc:1786] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.
/home/paperspace/.local/lib/python3.8/site-packages/keras/backend.py:450: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.
  warnings.warn('`tf.keras.backend.set_learning_phase` is deprecated and '
WARNING:tensorflow:From /home/paperspace/.local/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Use fn_output_signature instead
W0717 13:38:16.021436 140087941658368 deprecation.py:554] From /home/paperspace/.local/lib/python3.8/site-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.
Instructions for updating:
Use fn_output_signature instead
WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
W0717 13:38:35.720965 140087941658368 utils.py:76] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
W0717 13:39:01.945398 140087941658368 utils.py:76] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
W0717 13:39:26.008457 140087941658368 utils.py:76] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
WARNING:tensorflow:Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
W0717 13:39:51.917016 140087941658368 utils.py:76] Gradients do not exist for variables ['top_bn/gamma:0', 'top_bn/beta:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?
2022-07-17 13:40:34.322686: I tensorflow/core/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory
INFO:tensorflow:Step 100 per-step time 1.871s
I0717 13:41:22.914030 140137644001088 model_lib_v2.py:705] Step 100 per-step time 1.871s
INFO:tensorflow:{'Loss/classification_loss': 0.4775982,
 'Loss/localization_loss': 0.30682355,
 'Loss/regularization_loss': 0.028672347,
 'Loss/total_loss': 0.8130941,
 'learning_rate': 0.00416}
I0717 13:41:22.914931 140137644001088 model_lib_v2.py:708] {'Loss/classification_loss': 0.4775982,
 'Loss/localization_loss': 0.30682355,
 'Loss/regularization_loss': 0.028672347,
 'Loss/total_loss': 0.8130941,
 'learning_rate': 0.00416}
INFO:tensorflow:Step 200 per-step time 0.384s
I0717 13:42:00.502387 140137644001088 model_lib_v2.py:705] Step 200 per-step time 0.384s
INFO:tensorflow:{'Loss/classification_loss': 0.80225015,
 'Loss/localization_loss': 0.23041776,
 'Loss/regularization_loss': 0.0289109,
 'Loss/total_loss': 1.0615788,
 'learning_rate': 0.0073200003}
I0717 13:42:00.503137 140137644001088 model_lib_v2.py:708] {'Loss/classification_loss': 0.80225015,
 'Loss/localization_loss': 0.23041776,
 'Loss/regularization_loss': 0.0289109,
 'Loss/total_loss': 1.0615788,
 'learning_rate': 0.0073200003}
INFO:tensorflow:Step 300 per-step time 0.376s
I0717 13:42:38.106418 140137644001088 model_lib_v2.py:705] Step 300 per-step time 0.376s
INFO:tensorflow:{'Loss/classification_loss': 1.1065288,
 'Loss/localization_loss': 0.04400189,
 'Loss/regularization_loss': 0.02923251,
 'Loss/total_loss': 1.1797632,
 'learning_rate': 0.010480001}
I0717 13:42:38.107155 140137644001088 model_lib_v2.py:708] {'Loss/classification_loss': 1.1065288,
 'Loss/localization_loss': 0.04400189,
 'Loss/regularization_loss': 0.02923251,
 'Loss/total_loss': 1.1797632,
 'learning_rate': 0.010480001}
INFO:tensorflow:Step 400 per-step time 0.376s
I0717 13:43:15.665227 140137644001088 model_lib_v2.py:705] Step 400 per-step time 0.376s
INFO:tensorflow:{'Loss/classification_loss': 0.487589,
 'Loss/localization_loss': 0.06459406,
 'Loss/regularization_loss': 0.029603072,
 'Loss/total_loss': 0.5817861,
 'learning_rate': 0.0136400005}
I0717 13:43:15.666080 140137644001088 model_lib_v2.py:708] {'Loss/classification_loss': 0.487589,
 'Loss/localization_loss': 0.06459406,
 'Loss/regularization_loss': 0.029603072,
 'Loss/total_loss': 0.5817861,
 'learning_rate': 0.0136400005}
INFO:tensorflow:Step 500 per-step time 0.377s
I0717 13:43:53.363694 140137644001088 model_lib_v2.py:705] Step 500 per-step time 0.377s
INFO:tensorflow:{'Loss/classification_loss': 0.30813763,
 'Loss/localization_loss': 0.15945105,
 'Loss/regularization_loss': 0.029864084,
 'Loss/total_loss': 0.49745274,
 'learning_rate': 0.016800001}
I0717 13:43:53.364551 140137644001088 model_lib_v2.py:708] {'Loss/classification_loss': 0.30813763,
 'Loss/localization_loss': 0.15945105,
 'Loss/regularization_loss': 0.029864084,
 'Loss/total_loss': 0.49745274,
 'learning_rate': 0.016800001}
INFO:tensorflow:Step 600 per-step time 0.376s
I0717 13:44:31.005828 140137644001088 model_lib_v2.py:705] Step 600 per-step time 0.376s
INFO:tensorflow:{'Loss/classification_loss': 0.14375634,
 'Loss/localization_loss': 0.06852519,
 'Loss/regularization_loss': 0.029966393,
 'Loss/total_loss': 0.24224792,
 'learning_rate': 0.019960001}
I0717 13:44:31.006762 140137644001088 model_lib_v2.py:708] {'Loss/classification_loss': 0.14375634,
 'Loss/localization_loss': 0.06852519,
 'Loss/regularization_loss': 0.029966393,
 'Loss/total_loss': 0.24224792,
 'learning_rate': 0.019960001}
INFO:tensorflow:Step 700 per-step time 0.377s
I0717 13:45:08.718003 140137644001088 model_lib_v2.py:705] Step 700 per-step time 0.377s
INFO:tensorflow:{'Loss/classification_loss': 0.17033774,
 'Loss/localization_loss': 0.019284764,
 'Loss/regularization_loss': 0.029986884,
 'Loss/total_loss': 0.2196094,
 'learning_rate': 0.023120001}
I0717 13:45:08.718935 140137644001088 model_lib_v2.py:708] {'Loss/classification_loss': 0.17033774,
 'Loss/localization_loss': 0.019284764,
 'Loss/regularization_loss': 0.029986884,
 'Loss/total_loss': 0.2196094,
 'learning_rate': 0.023120001}
INFO:tensorflow:Step 800 per-step time 0.375s
I0717 13:45:46.210756 140137644001088 model_lib_v2.py:705] Step 800 per-step time 0.375s
INFO:tensorflow:{'Loss/classification_loss': 0.07108299,
 'Loss/localization_loss': 0.022301223,
 'Loss/regularization_loss': 0.030085169,
 'Loss/total_loss': 0.123469375,
 'learning_rate': 0.02628}
I0717 13:45:46.211443 140137644001088 model_lib_v2.py:708] {'Loss/classification_loss': 0.07108299,
 'Loss/localization_loss': 0.022301223,
 'Loss/regularization_loss': 0.030085169,
 'Loss/total_loss': 0.123469375,
 'learning_rate': 0.02628}
INFO:tensorflow:Step 900 per-step time 0.377s
I0717 13:46:23.880851 140137644001088 model_lib_v2.py:705] Step 900 per-step time 0.377s
INFO:tensorflow:{'Loss/classification_loss': 0.1875089,
 'Loss/localization_loss': 0.068536595,
 'Loss/regularization_loss': 0.030091498,
 'Loss/total_loss': 0.28613698,
 'learning_rate': 0.02944}
I0717 13:46:23.881527 140137644001088 model_lib_v2.py:708] {'Loss/classification_loss': 0.1875089,
 'Loss/localization_loss': 0.068536595,
 'Loss/regularization_loss': 0.030091498,
 'Loss/total_loss': 0.28613698,
 'learning_rate': 0.02944}
INFO:tensorflow:Step 1000 per-step time 0.373s
I0717 13:47:01.216650 140137644001088 model_lib_v2.py:705] Step 1000 per-step time 0.373s
INFO:tensorflow:{'Loss/classification_loss': 1.155892,
 'Loss/localization_loss': 0.15898634,
 'Loss/regularization_loss': 0.030342821,
 'Loss/total_loss': 1.3452212,
 'learning_rate': 0.0326}
I0717 13:47:01.217327 140137644001088 model_lib_v2.py:708] {'Loss/classification_loss': 1.155892,
 'Loss/localization_loss': 0.15898634,
 'Loss/regularization_loss': 0.030342821,
 'Loss/total_loss': 1.3452212,
 'learning_rate': 0.0326}
